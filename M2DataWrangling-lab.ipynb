{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "# **Data Wrangling Lab**\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Estimated time needed: **45 to 60** minutes\n"}, {"metadata": {}, "cell_type": "markdown", "source": "In this assignment you will be performing data wrangling.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Objectives\n"}, {"metadata": {}, "cell_type": "markdown", "source": "In this lab you will perform the following:\n"}, {"metadata": {}, "cell_type": "markdown", "source": "*   Identify duplicate values in the dataset.\n\n*   Remove duplicate values from the dataset.\n\n*   Identify missing values in the dataset.\n\n*   Impute the missing values in the dataset.\n\n*   Normalize data in the dataset.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Hands on Lab\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Import pandas module.\n"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Load the dataset into a dataframe.\n"}, {"metadata": {}, "cell_type": "code", "source": "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")\n#df", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Finding duplicates\n"}, {"metadata": {}, "cell_type": "markdown", "source": "In this section you will identify duplicate values in the dataset.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Find how many duplicate rows exist in the dataframe.\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\nprint(df.duplicated().sum())", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "154\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Removing duplicates\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Remove the duplicate rows from the dataframe.\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\ndf.drop_duplicates(inplace = True)", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Verify if duplicates were actually dropped.\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\nprint(df.duplicated().value_counts())", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "False    11398\ndtype: int64\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Finding Missing values\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Find the missing values for all columns.\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print(df.isnull().sum())", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Respondent                   0\nMainBranch                   0\nHobbyist                     0\nOpenSourcer                  0\nOpenSource                  81\nEmployment                   0\nCountry                      0\nStudent                     53\nEdLevel                    116\nUndergradMajor             740\nEduOther                   164\nOrgSize                     98\nDevType                     67\nYearsCode                    9\nAge1stCode                  13\nYearsCodePro                16\nCareerSat                    0\nJobSat                       1\nMgrIdiot                   498\nMgrMoney                   502\nMgrWant                    498\nJobSeek                      0\nLastHireDate                 0\nLastInt                    423\nFizzBuzz                    37\nJobFactors                   3\nResumeUpdate                41\nCurrencySymbol               0\nCurrencyDesc                 0\nCompTotal                  815\nCompFreq                   206\nConvertedComp              822\nWorkWeekHrs                125\nWorkPlan                   123\nWorkChallenge              168\nWorkRemote                   8\nWorkLoc                     32\nImpSyn                       5\nCodeRev                      1\nCodeRevHrs                2469\nUnitTests                   29\nPurchaseHow                198\nPurchaseWhat                38\nLanguageWorkedWith          11\nLanguageDesireNextYear     137\nDatabaseWorkedWith         456\nDatabaseDesireNextYear    1055\nPlatformWorkedWith         422\nPlatformDesireNextYear     561\nWebFrameWorkedWith        1413\nWebFrameDesireNextYear    1634\nMiscTechWorkedWith        2209\nMiscTechDesireNextYear    1474\nDevEnviron                  29\nOpSys                       34\nContainers                  82\nBlockchainOrg             2354\nBlockchainIs              2637\nBetterLife                 100\nITperson                    35\nOffOn                       38\nSocialMedia                301\nExtraversion                20\nScreenName                 513\nSOVisit1st                 325\nSOVisitFreq                  5\nSOVisitTo                    1\nSOFindAnswer                 3\nSOTimeSaved                 51\nSOHowMuchTime             1936\nSOAccount                    1\nSOPartFreq                1148\nSOJobs                       6\nEntTeams                     5\nSOComm                       0\nWelcomeChange               89\nSONewContent              1995\nAge                        297\nGender                      75\nTrans                      123\nSexuality                  547\nEthnicity                  683\nDependents                 144\nSurveyLength                19\nSurveyEase                  14\ndtype: int64\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Find out how many rows are missing in the column 'WorkLoc'\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\nprint(\"There are\", df['WorkLoc'].isnull().sum(), \"missing values in the column 'WorkLoc'\")\nprint(\"There are\", df['EdLevel'].isnull().sum(), \"missing values in the column 'EdLevel'\")\nprint(\"There are\", df['Country'].isnull().sum(), \"missing values in the column 'Country'\")", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "There are 32 missing values in the column 'WorkLoc'\nThere are 116 missing values in the column 'EdLevel'\nThere are 0 missing values in the column 'Country'\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Imputing missing values\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Find the  value counts for the column WorkLoc.\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\nprint('There are', df['WorkLoc'].nunique(), 'unique Work Locations in the survey:')\n\nprint('\\nWorkLoc                                    value count')      \nprint('-------                                    -----------')\nprint(df['WorkLoc'].value_counts())\n\nprint('\\n\\nThere are', df['Employment'].nunique(), 'unique Employment values in the survey:')\n\nprint('\\nEmployment        value count')      \nprint('----------        -----------')\nprint(df['Employment'].value_counts())\n\nprint('\\n\\nThere are', df['UndergradMajor'].nunique(), 'unique UndergradMajor values in the survey:')\n\nprint('\\nUndergradMajor        value count')      \nprint('---------------        -----------')\nprint(df['UndergradMajor'].value_counts())", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "There are 3 unique Work Locations in the survey:\n\nWorkLoc                                    value count\n-------                                    -----------\nOffice                                            6905\nHome                                              3638\nOther place, such as a coworking space or cafe     977\nName: WorkLoc, dtype: int64\n\n\nThere are 2 unique Employment values in the survey:\n\nEmployment        value count\n----------        -----------\nEmployed full-time    11113\nEmployed part-time      439\nName: Employment, dtype: int64\n\n\nThere are 12 unique UndergradMajor values in the survey:\n\nUndergradMajor        value count\n---------------        -----------\nComputer science, computer engineering, or software engineering          7053\nInformation systems, information technology, or system administration     806\nAnother engineering discipline (ex. civil, electrical, mechanical)        769\nWeb development or web design                                             417\nA natural science (ex. biology, chemistry, physics)                       409\nMathematics or statistics                                                 375\nA business discipline (ex. accounting, finance, marketing)                247\nA social science (ex. anthropology, psychology, political science)        212\nA humanities discipline (ex. literature, history, philosophy)             209\nFine arts or performing arts (ex. graphic design, music, studio art)      165\nI never declared a major                                                  126\nA health science (ex. nursing, pharmacy, radiology)                        24\nName: UndergradMajor, dtype: int64\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Identify the value that is most frequent (majority) in the WorkLoc column.\n"}, {"metadata": {}, "cell_type": "code", "source": "#make a note of the majority value here, for future reference\nprint(df['ConvertedComp'].mean())\nprint(df['ConvertedComp'].median())", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "131334.0025163094\n57744.0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\nimport numpy as np\n\nworkloc_highest = 'Office'\n\nmissing_data = df.isnull()\n#print(missing_data.head(5))\n\nprint('\\nValue counts for missing data in WorkLoc:\\n')\nprint( missing_data['WorkLoc'].value_counts())\n\n\nprint('\\nHere are the first 10 rows missing values for WorkLoc:')\nprint(df[missing_data['WorkLoc']][['Respondent','WorkLoc']].head(10))\n\ndf['WorkLoc'].replace(np.nan, workloc_highest, inplace=True)", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "\nValue counts for missing data in WorkLoc:\n\nFalse    11520\nTrue        32\nName: WorkLoc, dtype: int64\n\nHere are the first 10 rows missing values for WorkLoc:\n      Respondent WorkLoc\n130          285     NaN\n242          550     NaN\n866         1847     NaN\n1455        2826     NaN\n1753        3536     NaN\n2339        4768     NaN\n2689        5562     NaN\n2788        5769     NaN\n3165        6613     NaN\n3213        6721     NaN\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "After imputation there should ideally not be any empty rows in the WorkLoc column.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Verify if imputing was successful.\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\nprint('\\nNew value counts for missing data in WorkLoc:\\n')\nprint(missing_data['WorkLoc'].value_counts())", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "\nNew value counts for missing data in WorkLoc:\n\nFalse    11520\nTrue        32\nName: WorkLoc, dtype: int64\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Normalizing data\n"}, {"metadata": {}, "cell_type": "markdown", "source": "There are two columns in the dataset that talk about compensation.\n\nOne is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n\nThe other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\".\n\nThis makes it difficult to compare the total compensation of the developers.\n\nIn this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n\nOnce this column is ready, it makes comparison of salaries easy.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "List out the various categories in the column 'CompFreq'\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\nprint(df['CompFreq'].value_counts())", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "Yearly     6163\nMonthly    4846\nWeekly      337\nName: CompFreq, dtype: int64\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Double click to see the **Hint**.\n\n<!--\n\nUse the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n\nIf the CompFreq is Yearly then use the exising value in CompTotal\nIf the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\nIf the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n\n-->\n"}, {"metadata": {}, "cell_type": "code", "source": "# your code goes here\ndf.loc[df['CompFreq'] == 'Yearly', 'NormalizedAnnualCompensation']  = 1  * df['CompTotal']\ndf.loc[df['CompFreq'] == 'Monthly', 'NormalizedAnnualCompensation'] = 12 * df['CompTotal']\ndf.loc[df['CompFreq'] == 'Weekly', 'NormalizedAnnualCompensation']  = 52 * df['CompTotal']\n\n\ndf[['CompTotal','CompFreq','NormalizedAnnualCompensation']].head(20)\n\ndf['NormalizedAnnualCompensation'].median()", "execution_count": 24, "outputs": [{"output_type": "execute_result", "execution_count": 24, "data": {"text/plain": "100000.0"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Authors\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Ramesh Sannareddy\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Other Contributors\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Rav Ahuja\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Change Log\n"}, {"metadata": {}, "cell_type": "markdown", "source": "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n| ----------------- | ------- | ----------------- | ---------------------------------- |\n| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Copyright \u00a9 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2022-01-01&cm_mmc=Email_Newsletter-\\_-Developer_Ed%2BTech-\\_-WW_WW-\\_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}